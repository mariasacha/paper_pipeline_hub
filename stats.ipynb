{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import scikit_posthocs as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_raincloud_with_stats_trial(parameters, params, n_trials=5, stimvals=[1e-3], pick_stim=1, conditions= ['wake', 'nmda', 'gaba', 'sleep'],  \n",
    "                              colors = [ \"steelblue\", '#6d0a26', '#9b6369', '#c0b3b4'],\n",
    "                              dx='stim', dy='PCI', dhue='cond', ort='v', sigma=0.2, local_folder=False):\n",
    "    \"\"\"\n",
    "    df\n",
    "    pick_stim: the stimulus for which you will compare\n",
    "    colors should be at least as many as the conditions\n",
    "    dx, dy, dhue, ort, sigma: parameters for the raincloud\n",
    "    \"\"\"\n",
    "    if local_folder:\n",
    "        print(\"Loading paper params:\")\n",
    "        params = [[5, 5.0, 60], [30, 3.75, 60], [30, 7.0, 60], [120, 5.0, 60]] # b_e, tau, nseeds\n",
    "        conditions = ['wake', 'nmda', 'gaba', 'sleep'] #conditions that the params describe\n",
    "        stimvals = [1e-5, 1e-4, 1e-3] #stimvals to load\n",
    "        n_trials=5\n",
    "        for i in range(len(conditions)):\n",
    "            print(f\"For {conditions[i]} : b_e={params[i][0]}, tau={params[i][1]}\")\n",
    "        print(f\"Seeds = {params[0][2]}, n_trials={n_trials}, stimvals={stimvals}\")\n",
    "    PCI_all = create_PCI_all(parameters, params, n_trials=n_trials,stimvals = stimvals, local_folder=local_folder)\n",
    "\n",
    "    print(\"Creating dataframe\")\n",
    "    df = create_dataset_for_raincloud(PCI_all, stimvals = stimvals, conditions= conditions)\n",
    "#Check if there are more than one pick_stims:\n",
    "    if type(pick_stim) is list and len(pick_stim)>1: \n",
    "        df_use = df[df['stim'].isin(pick_stim)]\n",
    "        if len(np.unique(df_use['stim']))>1:\n",
    "            plot_all_stimuli(df_use, sigma)\n",
    "        else:\n",
    "            print(f\"Only stim = {np.unique(df_use['stim'])} exists for these parameters\\nTry again with the correct value in pick_stim\")\n",
    "    else:\n",
    "        if type(pick_stim) is list:\n",
    "            pick_stim = pick_stim[0]\n",
    "        df_use = df[df['stim']==pick_stim]\n",
    "        # df_use = df\n",
    "        if colors and len(colors)<=len(conditions):\n",
    "            pal = sns.color_palette(colors)\n",
    "        else:\n",
    "            pal = sns.color_palette('tab20')\n",
    "    print(\"Creating PCI_all\")\n",
    "\n",
    "    # df_use = df[df['stim']==pick_stim]\n",
    "    return PCI_all, df_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [[5, 3.75, 2], [60, 5, 2]] # b_e, tau, nseeds\n",
    "conditions = ['nmda', 'sleep'] #conditions that the params describe - used for the x tick labels\n",
    "stimvals = [1e-3] #stimvals to load\n",
    "n_trials=1 #how many trials were used for the PCI\n",
    "\n",
    "pick_stim = [1] # stimulus strength to plot\n",
    "\n",
    "#set this to True if you want to plot the already run stims, it will load params automatically\n",
    "local_folder= True \n",
    "\n",
    "\n",
    "PCI_all, df = plot_raincloud_with_stats_trial(parameters, params, n_trials=n_trials, stimvals=stimvals, pick_stim=pick_stim, conditions= conditions, local_folder=local_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the value and group columns as per the user's request\n",
    "val_col = 'PCI'\n",
    "group_col = 'cond'\n",
    "\n",
    "# Rank the data\n",
    "df['rank'] = df[val_col].rank()\n",
    "\n",
    "# Perform the post-hoc Conover test\n",
    "conover_results = sp.posthoc_conover(df, val_col=val_col, group_col=group_col, p_adjust='holm')\n",
    "\n",
    "# Iterating over the pairs of groups in the dataset to calculate U and T-statistics\n",
    "group_pairs = [(group1, group2) for i, group1 in enumerate(df[group_col].unique()) \n",
    "               for group2 in df[group_col].unique()[i+1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print the median for each group\n",
    "median_values = df.groupby(group_col)[val_col].median()\n",
    "print(\"Median values by group:\")\n",
    "print(median_values)\n",
    "\n",
    "# Calculate and print the 25th and 75th percentiles for each group\n",
    "quantiles = df.groupby(group_col)[val_col].quantile([0.25, 0.75]).unstack()\n",
    "print(\"\\n25th and 75th percentiles by group:\")\n",
    "print(quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data\n",
    "groups = df.groupby(group_col)[val_col].apply(list)\n",
    "\n",
    "# Extract data for each group\n",
    "group_data = [groups[group] for group in groups.index]\n",
    "\n",
    "# Perform the Kruskal-Wallis H-test\n",
    "kruskal_result = stats.kruskal(*group_data)\n",
    "\n",
    "# Print the result\n",
    "print(f\"Krack-Wallis H-statistic: {kruskal_result.statistic}\")\n",
    "print(f\"P-value: {kruskal_result.pvalue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Post_hoc = sp.posthoc_conover(df, val_col='PCI', group_col='cond', p_adjust='holm')\n",
    "Post_hoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the T-statistic for each pair\n",
    "t_stats = {}\n",
    "for group1, group2 in group_pairs:\n",
    "    groupA = df[df[group_col] == group1]['rank']\n",
    "    groupB = df[df[group_col] == group2]['rank']\n",
    "    \n",
    "    # Mann-Whitney U test between two groups\n",
    "    u_stat, p_value = stats.mannwhitneyu(groupA, groupB, alternative='two-sided')\n",
    "    \n",
    "    # Convert U-statistic to T-statistic approximation\n",
    "    n1 = len(groupA)\n",
    "    n2 = len(groupB)\n",
    "    \n",
    "    print(n1, n2)\n",
    "    # Calculate the T-statistic (based on U approximation)\n",
    "    t_stat = (u_stat - n1 * n2 / 2) / (n1 * n2 * (n1 + n2 + 1) / 12)**0.5\n",
    "    \n",
    "    # Store the result\n",
    "    t_stats[(group1, group2)] = t_stat\n",
    "\n",
    "# Output the T-statistics for each group pair\n",
    "t_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sample size for each group\n",
    "sample_size = 60\n",
    "\n",
    "# Function to calculate effect size r\n",
    "def calculate_effect_size_r(t_stat, sample_size):\n",
    "    total_n = 2 * sample_size  # Since each comparison involves two groups\n",
    "    r = t_stat / np.sqrt(total_n)\n",
    "    return r\n",
    "\n",
    "# Dictionary to store the effect sizes\n",
    "effect_sizes = {}\n",
    "\n",
    "# Calculate the effect size r for each pairwise comparison\n",
    "for pair, t_stat in t_stats.items():\n",
    "    r = calculate_effect_size_r(t_stat, sample_size)\n",
    "    effect_sizes[pair] = r\n",
    "\n",
    "# Output the effect sizes\n",
    "effect_sizes"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
